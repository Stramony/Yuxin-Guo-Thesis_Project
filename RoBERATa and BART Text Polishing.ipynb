{"cells":[{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["from transformers import RobertaTokenizer, RobertaForSequenceClassification, BartTokenizer, BartForConditionalGeneration\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["# RoBERATa and BART to Analysis Sentiment and Text Polishing"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: negative, Predicted Scenario: friend\n"]}],"source":["def load_roberta_model():\n","    tokenizer = RobertaTokenizer.from_pretrained('roberta_saved_model')\n","    model = RobertaForSequenceClassification.from_pretrained('roberta_saved_model', num_labels=4)  \n","    model.eval()  # Switch to evaluation mode\n","    return tokenizer, model\n","\n","# Sentiment and scenario prediction function\n","def predict_sentiment_and_scenario(model, tokenizer, text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    logits = outputs.logits\n","    predictions = torch.sigmoid(logits)  # Multi-label classification, use sigmoid activation function\n","\n","    # Predicted sentiment and scenario\n","    work, friend, family, sentiment_numeric = predictions[0].tolist()\n","\n","    # Judge whether the sentiment is positive or negative\n","    sentiment = \"positive\" if sentiment_numeric >= 0.5 else \"negative\"\n","\n","    # Scenario label judgment\n","    if work >= 0.5:\n","        scenario = \"work\"\n","    elif friend >= 0.5:\n","        scenario = \"friend\"\n","    elif family >= 0.5:\n","        scenario = \"family\"\n","    else:\n","        scenario = \"other\"\n","    \n","    return sentiment, scenario\n","\n","# Load RoBERTa model\n","tokenizer, roberta_model = load_roberta_model()\n","\n","# Input text\n","text_input = \"I hate you, you are so annoying.\"\n","predicted_sentiment, predicted_scenario = predict_sentiment_and_scenario(roberta_model, tokenizer, text_input)\n","\n","print(f\"Predicted Sentiment: {predicted_sentiment}, Predicted Scenario: {predicted_scenario}\")"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Refined Text with BART:\n","Please rewrite the following message to make it sound more friendly and casual: 'I hate you, you are so annoying' 'I love you, but you're so annoying.' 'I'm so angry at you, I can't stand you' 'You're annoying, but I'm not mad at you. You're annoying'\n"]}],"source":["# Load BART model and tokenizer\n","from transformers import BartTokenizer, BartForConditionalGeneration\n","\n","def load_bart_model():\n","    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n","    model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n","    return tokenizer, model\n","\n","# According to sentiment and scenario, refine negative text\n","def refine_negative_text_bart(model, tokenizer, scenario, original_text):\n","    if scenario == \"work\":\n","        prompt = f\"Please rewrite the following message to make it polite and professional: '{original_text}'\"\n","    elif scenario == \"friend\":\n","        prompt = f\"Please rewrite the following message to make it sound more friendly and casual: '{original_text}'\"\n","    elif scenario == \"family\":\n","        prompt = f\"Please rewrite the following message to make it warm and understanding: '{original_text}'\"\n","    \n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    outputs = model.generate(\n","        inputs[\"input_ids\"], \n","        max_length=100,  # Adjust value is 100 appropriately to avoid text truncation\n","        num_return_sequences=1, \n","        temperature=0.7,  # Adjust the generation diversity appropriately\n","        top_k=50 # Limit the top k high probability vocabulary words to avoid generating unreasonable text\n","    )\n","    refined_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return refined_text\n","\n","# Load BART model and tokenizer\n","# Code from: https://www.kaggle.com/code/shaunshibu/ai-gen-text-ident-multiple-model-training-shaun\n","bart_tokenizer, bart_model = load_bart_model()\n","\n","\n","# Polishing the text if the sentiment is negative\n","if predicted_sentiment == \"negative\":\n","    refined_text_bart = refine_negative_text_bart(bart_model, bart_tokenizer, predicted_scenario, text_input)\n","    print(f\"Refined Text with BART:\\n{refined_text_bart}\")\n","else:\n","    print(\"The input text is already positive, no refinement needed.\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from rouge_score import rouge_scorer\n","from bert_score import score as bert_score"]},{"cell_type":"markdown","metadata":{},"source":["Code from: https://haticeozbolat17.medium.com/bertscore-and-rouge-two-metrics-for-evaluating-text-summarization-systems-6337b1d98917"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ROUGE-1 F1: 0.7097\n","ROUGE-2 F1: 0.3448\n","ROUGE-L F1: 0.4516\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b92e9acc44d4a128acb9fd586777bc8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08edc21cfa0842b18b1d6759ef6c1c73","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 2.49 seconds, 0.40 sentences/sec\n","BERTScore Precision: 0.9245\n","BERTScore Recall: 0.9233\n","BERTScore F1: 0.9239\n"]}],"source":["# Original text and reference text\n","original_text = \"I currently have too much work and I can’t complete the new task tasks.\"  # 原始输入文本\n","reference_text = \"I can't complete the task tasks because I'm currently too busy with other work.\"  # 参考文本\n","\n","# Calculate ROUGE scores\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","rouge_scores = scorer.score(original_text, reference_text)\n","\n","print(f\"ROUGE-1 F1: {rouge_scores['rouge1'].fmeasure:.4f}\")\n","print(f\"ROUGE-2 F1: {rouge_scores['rouge2'].fmeasure:.4f}\")\n","print(f\"ROUGE-L F1: {rouge_scores['rougeL'].fmeasure:.4f}\")\n","\n","# Calculate BERTScore\n","P, R, F1 = score([original_text], [reference_text], lang=\"en\", verbose=True)\n","\n","print(f\"BERTScore Precision: {P.mean().item():.4f}\")\n","print(f\"BERTScore Recall: {R.mean().item():.4f}\")\n","print(f\"BERTScore F1: {F1.mean().item():.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Code Reference List\n","\n","Hatice Özbolat (2023). BERTScore and ROUGE: Two Metrics for Evaluating Text Summarization Systems. [online] Medium. Available at: https://haticeozbolat17.medium.com/bertscore-and-rouge-two-metrics-for-evaluating-text-summarization-systems-6337b1d98917 [Accessed 19 Sep. 2024].\n","\n","shaunshibu (2023). AI Gen Text Ident, Multiple Model Training - Shaun. [online] Kaggle.com. Available at: https://www.kaggle.com/code/shaunshibu/ai-gen-text-ident-multiple-model-training-shaun [Accessed 19 Sep. 2024]."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5695840,"sourceId":9387283,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
