{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel, RobertaTokenizer, RobertaForSequenceClassification\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["# RoBERATa and GPT-2 to Analysis Sentiment and Text Polishing"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: negative, Predicted Scenario: work\n"]}],"source":["def load_roberta_model():\n","    tokenizer = RobertaTokenizer.from_pretrained('roberta_saved_model')\n","    model = RobertaForSequenceClassification.from_pretrained('roberta_saved_model', num_labels=4)# 4 labels: work, friend, family, sentiment\n","    model.eval() \n","    return tokenizer, model\n","\n","# Sentiment and Scenario Prediction Function\n","def predict_sentiment_and_scenario(model, tokenizer, text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    logits = outputs.logits\n","    predictions = torch.sigmoid(logits) #Multi-label classification, use sigmoid activation function\n","\n","    #  Predicted labels: work, friend, family, sentiment\n","    work, friend, family, sentiment_numeric = predictions[0].tolist()\n","\n","    # Sentiment prediction: positive or negative\n","    sentiment = \"positive\" if sentiment_numeric >= 0.5 else \"negative\"\n","\n","    # Scenario prediction: work, friend, family, other\n","    if work >= 0.5:\n","        scenario = \"work\"\n","    elif friend >= 0.5:\n","        scenario = \"friend\"\n","    elif family >= 0.5:\n","        scenario = \"family\"\n","    else:\n","        scenario = \"other\"\n","    \n","    return sentiment, scenario\n","\n","# Load RoBERTa model\n","tokenizer, roberta_model = load_roberta_model()\n","\n","# Input text \n","text_input = \"I don’t think you’re right for the job because you’re doing it all wrong.\"\n","predicted_sentiment, predicted_scenario = predict_sentiment_and_scenario(roberta_model, tokenizer, text_input)\n","\n","print(f\"Predicted Sentiment: {predicted_sentiment}, Predicted Scenario: {predicted_scenario}\")"]},{"cell_type":"markdown","metadata":{},"source":["Code from https://huggingface.co/docs/transformers/model_doc/gpt2"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Refined Text:\n","Refine this message in a polite and professional way: I don’t think you’re right for the job because you’re doing it all wrong. I’t think you’re doing it all wrong because you’re doing it all wrong because you’re doing it all wrong because you’\n"]}],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# Load GPT-2 model and tokenizer\n","def load_gpt2_model():\n","    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","    model = GPT2LMHeadModel.from_pretrained('gpt2')\n","    return tokenizer, model\n","\n","# Refine negative text based on sentiment and scenario\n","def refine_negative_text(model, tokenizer, scenario, original_text):\n","    if scenario == \"work\":\n","        prompt = f\"Refine this message in a polite and professional way: {original_text}\"\n","    elif scenario == \"friend\":\n","        prompt = f\"Refine this message to sound more friendly and casual: {original_text}\"\n","    elif scenario == \"family\":\n","        prompt = f\"Refine this message to sound warm and understanding: {original_text}\"\n","    \n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    outputs = model.generate(inputs[\"input_ids\"], max_length=70, num_return_sequences=1)\n","    refined_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return refined_text\n","\n","# Load GPT-2 model and tokenizer\n","gpt2_tokenizer, gpt2_model = load_gpt2_model()\n","\n","# If the sentiment is negative, refine the text, otherwise, no refinement needed\n","if predicted_sentiment == \"negative\":\n","    refined_text = refine_negative_text(gpt2_model, gpt2_tokenizer, predicted_scenario, text_input)\n","    print(f\"Refined Text:\\n{refined_text}\")\n","else:\n","    print(\"The input text is already positive, no refinement needed.\")"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting bert-score\n","  Obtaining dependency information for bert-score from https://files.pythonhosted.org/packages/c6/8c/bc5457de4c004b1a623b31f7bc8d0375fb699b7d67df11879098b4b7b7c8/bert_score-0.3.13-py3-none-any.whl.metadata\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Collecting absl-py (from rouge-score)\n","  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n","  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: nltk in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: numpy in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from rouge-score) (1.26.0)\n","Requirement already satisfied: six>=1.14.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: torch>=1.0.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from bert-score) (2.4.0)\n","Requirement already satisfied: pandas>=1.0.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from bert-score) (2.1.1)\n","Requirement already satisfied: transformers>=3.0.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from bert-score) (4.44.2)\n","Requirement already satisfied: requests in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from bert-score) (2.31.0)\n","Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from bert-score) (4.66.1)\n","Requirement already satisfied: matplotlib in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from bert-score) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from bert-score) (23.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n","Requirement already satisfied: filelock in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.12.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n","Requirement already satisfied: sympy in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.2)\n","Requirement already satisfied: jinja2 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n","Requirement already satisfied: fsspec in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=1.0.0->bert-score) (2023.9.2)\n","Requirement already satisfied: colorama in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.24.6)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2023.10.3)\n","Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from matplotlib->bert-score) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from matplotlib->bert-score) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from matplotlib->bert-score) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from matplotlib->bert-score) (10.0.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from matplotlib->bert-score) (3.1.1)\n","Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from matplotlib->bert-score) (6.1.0)\n","Requirement already satisfied: click in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from nltk->rouge-score) (1.3.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->bert-score) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->bert-score) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->bert-score) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->bert-score) (2023.7.22)\n","Requirement already satisfied: zipp>=3.1.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->bert-score) (3.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\tobys\\miniconda3\\envs\\nlp\\lib\\site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","   ---------------------------------------- 0.0/61.1 kB ? eta -:--:--\n","   --------------------------------- ------ 51.2/61.1 kB 1.3 MB/s eta 0:00:01\n","   ---------------------------------------- 61.1/61.1 kB 1.1 MB/s eta 0:00:00\n","Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py): started\n","  Building wheel for rouge-score (setup.py): finished with status 'done'\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24970 sha256=8b27ebb202b4445fb80d2d22de4d10cd45426e45480351550187e4dd08cb0f92\n","  Stored in directory: c:\\users\\tobys\\appdata\\local\\pip\\cache\\wheels\\9b\\3d\\39\\09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n","Successfully built rouge-score\n","Installing collected packages: absl-py, rouge-score, bert-score\n","Successfully installed absl-py-2.1.0 bert-score-0.3.13 rouge-score-0.1.2\n"]}],"source":["!pip install rouge-score bert-score"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Original text and refined text\n","original_text = text_input\n","if predicted_sentiment == \"negative\":\n","    generated_text = refined_text\n","else:\n","    generated_text = text_input # If the text is positive, no refinement needed\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from rouge_score import rouge_scorer\n","from bert_score import score"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ROUGE-1 F1: 0.5600\n","ROUGE-2 F1: 0.3478\n","ROUGE-L F1: 0.5600\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d67c782d383a4bab823d8e4b9a72f1ef","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"742532135b2842dfbde0123a05f62f88","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 2.66 seconds, 0.38 sentences/sec\n","BERTScore Precision: 0.9159\n","BERTScore Recall: 0.9645\n","BERTScore F1: 0.9396\n"]}],"source":["original_text = \"I don’t think you’re right for the job because you’re doing it all wrong.\"  # Original text\n","reference_text = \"I think you are doing it all wrong.\" # Reference text\n","\n","# Calculate ROUGE scores\n","scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","rouge_scores = scorer.score(original_text, reference_text)\n","\n","print(f\"ROUGE-1 F1: {rouge_scores['rouge1'].fmeasure:.4f}\")\n","print(f\"ROUGE-2 F1: {rouge_scores['rouge2'].fmeasure:.4f}\")\n","print(f\"ROUGE-L F1: {rouge_scores['rougeL'].fmeasure:.4f}\")\n","\n","# Calculate BERTScore\n","P, R, F1 = score([original_text], [reference_text], lang=\"en\", verbose=True)\n","\n","print(f\"BERTScore Precision: {P.mean().item():.4f}\")\n","print(f\"BERTScore Recall: {R.mean().item():.4f}\")\n","print(f\"BERTScore F1: {F1.mean().item():.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Code Reference List\n","\n","Hugging Face (n.d.). OpenAI GPT2. [online] huggingface.co. Available at: https://huggingface.co/docs/transformers/model_doc/gpt2 [Accessed 19 Sep. 2024]."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5695840,"sourceId":9387283,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
